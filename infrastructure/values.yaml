imageCredentials:
  dockeryuuvisorg:
    registry: docker.yuuvis.org
    username:
    password:

yuuvis:
  # !!! Change before running
  # replace the value with the namespace you intent to use for the yuuvis API services
  # this chart creates a k8s job that generatey a selfsigned certificate and deploys the
  # crt file as a secret to the given namespace
  namespaces:
    yuuvis: yuuvis
    infrastructure: infrastructure
  authentication:
    # we assume test deployment in minikube
    # ip is the ip of the vm minikube creates
    # to get the ip: minikube ip
    ip: 127.0.0.1
    port: 30080
  labels:
    app: yuuvis
  db:
    name: yuuvis
    user: yuuvis
    password: changeme
  keycloak:
    nodePort: 30111
    createSelfSignedCert:
      docker:
        image: docker.yuuvis.org/yuuvis/helper/create-selfsigned-cert
        tag: jre11
        secret: dockeryuuvisorg
      nodeSelector: {}
      priorityClassName: ""
      tolerations: []
      nodeAffinity: {}
      podAffinity: {}
      podAntiAffinity: {}
  git:
    user: yuuvis
    password: changeme
    initcontainer:
      image: docker.yuuvis.org/yuuvis/helper/init-helper:2023-12-03
      secret: dockeryuuvisorg
      nodeSelector: {}
      priorityClassName: ""
      tolerations: []
      nodeAffinity: {}
      podAffinity: {}
      podAntiAffinity: {}


elasticsearch:
  image: docker.yuuvis.org/yuuvis/elasticsearch:2024-12-09
  imagePullPolicy: IfNotPresent
  imagePullSecret: dockeryuuvisorg
  storage: 100Gi
  storageClassName: standard
  port: 9300
  targetPort: 9300
  port2: 9200
  targetPort2: 9200
  # Default values if high availability is disabled. Nodes function as both data and master nodes simultaneously.
  nodes: 1
  initial_master_nodes: elasticsearch-0  
  memory: -Xms1024m -Xmx1024m
  requests:
    memory: 2Gi # always double of JVM memory setting
  pdb:    
    # pdb requires instances > 1 and minAvailable < instances,
    # otherwise draining nodes will deadlock!
    enabled: false

    # set `minAvailable: null` if you want to use maxUnavailable instead
    minAvailable: 1
  nodeSelector: {}
  priorityClassName: ""
  tolerations: []
  nodeAffinity: {}
  podAffinity: {}
  podAntiAffinity: {}
  highAvailability:
    enabled: false
    # Combined memory of all elasticsearch nodes should not exceed 50% of total memory available on k8s node.
    data:
      nodes: 2
      storage: 200Gi
      memory: -Xms4096m -Xmx4096m
      requests:
        memory: 8Gi # always double of JVM memory setting
      pdb:    
        # pdb requires instances > 1 and minAvailable < instances,
        # otherwise draining nodes will deadlock!
        enabled: false
      
        # set `minAvailable: null` if you want to use maxUnavailable instead
        minAvailable: 1
      nodeSelector: {}
      priorityClassName: ""
      tolerations: []
      nodeAffinity: {}
      podAffinity: {}
      podAntiAffinity: {}
    master:
      nodes: 3
      storage: 50Gi
      memory: -Xms1024m -Xmx1024m
      requests:
        memory: 2Gi # always double of JVM memory setting
      initial_master_nodes: elasticsearch-master-0, elasticsearch-master-1, elasticsearch-master-2
      pdb:    
        # pdb requires instances > 1 and minAvailable < instances,
        # otherwise draining nodes will deadlock!
        enabled: false
        
        # set `minAvailable: null` if you want to use maxUnavailable instead
      minAvailable: 1
      nodeSelector: {}
      priorityClassName: ""
      tolerations: []
      nodeAffinity: {}
      podAffinity: {}
      podAntiAffinity: {}
  

postgresql:
  enabled: true
  fullnameOverride: postgresql
  architecture: standalone
  global:
    postgresql:
      auth:
        postgresPassword: changeme
      servicePort: 5432
  resources:
    requests:
      memory: 128Mi
      cpu: 50m
  livenessProbe:
    enabled: false
  readinessProbe:
    enabled: false
  primary:
    initdb:
      scriptsConfigMap: postgresql-initdb
    extendedConfiguration: | 
      max_connections=400
      shared_buffers='128MB'
    persistence:
      storageClass: standard
      size: 50Gi

rabbitmq:
  enabled: true
  fullnameOverride: rabbitmq
  auth:
    username: rodger
    password: changeme
  extraPlugins: "rabbitmq_auth_backend_ldap rabbitmq_prometheus"
  extraConfiguration: |-
    #default_vhost = {{ .Release.Namespace }}-vhost
    #disk_free_limit.absolute = 50MB
    #load_definitions = /app/load_definition.json
  persistence:
    enabled: true
    storageClass: standard
    size: 1Gi
    
gitea:
  enabled: true
  fullnameOverride: gitea
  gitea:
    admin:
      password: changeme
    config:
      database: 
        DB_TYPE: sqlite3
      service:
        DISABLE_REGISTRATION: true
      queue:
        TYPE: level
      session:
        PROVIDER: memory
        PROVIDER_CONFIG: data/sessions
      cache:
        ENABLED: true
        ADAPTER: memory
  redis-cluster:
    enabled: false
  postgresql:
    enabled: false
  postgresql-ha:
    enabled: false
  persistence:
    enabled: true
    size: 1Gi
  
minio:
  enabled: true
  fullnameOverride: minio
  mode: standalone
  rootUser: minio
  rootPassword: "changeme"
  persistence:
    enabled: true
    storageClass: standard
    size: 10Gi
  resources:
    requests:
      memory: 1Gi
  users:
  - accessKey: console
    secretKey: changeme
    policy: consoleAdmin
  - accessKey: MGMWCOYTDUSLNCFE
    secretKey: changeme
    policy:  readwrite
    
keycloak:
  enabled: true
  # if true, a selfsigned certificate is created, keycloak is configured to use the
  # the selfsigned cert and an extra k8s service keycloak-https is deployed
  # further a job is used to create the namespace with the name from yuuvis.namespaces.yuuvis and create a secret with the cert
  # if a selfsigned cert is used the yuuvis services authentication, system and tenant-management
  # deployments must be configured to mount the secret
  # IMPORTANT: if no https is used, you must change the keycloak.http.internalScheme
  createselfsignedcert: true
  fullnameOverride: "keycloak"
  image:
    repository: docker.yuuvis.org/yuuvis/keycloak
    tag: "26.0.5-stable1"
    pullPolicy: IfNotPresent
  imagePullSecrets: 
   - name: dockeryuuvisorg
  http:
    # For backwards compatibility reasons we set this to the value used by previous Keycloak versions.
    relativePath: "/auth"
    internalPort: http-internal
    # change if no selfsigned cert is used
    internalScheme: HTTPS
  database:
    vendor: postgres
    hostname: postgresql 
    port: 5432
    database: keycloak
    username: keycloak
    password: changeme
  secrets:
    keycloakuser:
      stringData:
        user: keycloak
        password: changeme
  extraVolumes: |
    {{- if .Values.createselfsignedcert }}
    - name: tls-secret
      secret:
        secretName: keycloak-selfsigned-tls-secret
    {{- end }}
  extraVolumeMounts: |
    {{- if .Values.createselfsignedcert }}
    - name: tls-secret
      mountPath: "/opt/keycloak/conf/tls"
      readOnly: true
      {{- end }}
  command:
    - /opt/keycloak/bin/kc.sh
    - --verbose
    - start
    - --hostname-strict=false
    - --http-enabled=true
    - --proxy-headers=xforwarded
    - --spi-events-listener-jboss-logging-success-level=info
    - --spi-events-listener-jboss-logging-error-level=warn
  extraEnv: |
    - name: KEYCLOAK_ADMIN
      valueFrom:
        secretKeyRef:
          name: {{ include "keycloak.fullname" . }}-keycloakuser
          key: user
    - name: KEYCLOAK_ADMIN_PASSWORD
      valueFrom:
        secretKeyRef:
          name: {{ include "keycloak.fullname" . }}-keycloakuser
          key: password
    - name: KC_CACHE
      value: local
    {{- if .Values.createselfsignedcert }}
    - name: KC_HTTPS_CERTIFICATE_FILE
      value: /opt/keycloak/conf/tls/tls.crt
    - name: KC_HTTPS_CERTIFICATE_KEY_FILE
      value: /opt/keycloak/conf/tls/tls.key
    {{- end }}
  cache:
    stack: custom
  resources:
    requests:
      cpu: "1"
      memory: "512Mi"
    limits:
      cpu: "3"
      memory: "1536Mi"

redis:
  enabled: true
  fullnameOverride: redis
  ## Cluster settings
  architecture: standalone
  auth:
    enabled: false
    password: changeme
  master:
    livenessProbe:
      initialDelaySeconds: 600
    persistence:
      enabled: true
      storageClass: standard
      size: 1Gi
